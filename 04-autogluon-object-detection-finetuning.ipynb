{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d64601b5-91b1-41ef-bf34-3f27e920e264",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Autogluon fine tuning 예시\n",
    "\n",
    "- 새로운 class에 대해서 성능이 잘 나오는 object detection model을 fine-tuning 하는 예시입니다 : [참고](https://auto.gluon.ai/stable/tutorials/multimodal/object_detection/finetune/detection_high_performance_finetune_coco.html)\n",
    "- 앞의 노트북에서 autogluon을 설치했다고 가정합니다. (설치하지 않았다면 앞의 노트북 참고해서 설치할 것)\n",
    "- 앞의 노트북에서 데이터를 다운로드 했다고 가정합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e45116-ce5d-40d5-8693-7a7fff3f5cc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip list | grep autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d05313-1f7e-41c1-b3b1-fdb0d1c75e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9661b956-e4d0-4276-9bfb-d4d7d847b58f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"data\", \"pothole\")\n",
    "train_path = os.path.join(data_dir, \"Annotations\", \"usersplit_train_cocoformat.json\")\n",
    "val_path = os.path.join(data_dir, \"Annotations\", \"usersplit_val_cocoformat.json\")\n",
    "test_path = os.path.join(data_dir, \"Annotations\", \"usersplit_test_cocoformat.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676b4634-71f3-47c6-a948-ba6d1993cfb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mmdet.apis import init_detector, inference_detector\n",
    "import mmcv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d9d0710-930f-49bc-89f9-818383917dc7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.multimodal import MultiModalPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e017001a-9f19-4cb6-8bac-73faee19e763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# checkpoint_name = \"vfnet_r50_fpn_mdconv_c3-c5_mstrain_2x_coco\"  # 튜토리얼 사용 모델\n",
    "# checkpoint_name = \"vfnet_r50_fpn_mstrain_2x_coco\"\n",
    "checkpoint_name = \"yolox_x_8x8_300e_coco\"\n",
    "num_gpus = -1  # use all GPUs\n",
    "val_metric = \"map\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238396aa-8f6c-42c5-99c1-e41b4e6a2a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "predictor = MultiModalPredictor(\n",
    "    hyperparameters={\n",
    "        \"model.mmdet_image.checkpoint_name\": checkpoint_name,\n",
    "        \"env.num_gpus\": num_gpus,\n",
    "        \"optimization.val_metric\": val_metric,\n",
    "    },\n",
    "    problem_type=\"object_detection\",\n",
    "    sample_data_path=train_path,\n",
    "    path=\"./ag-trained-models\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31764e29-8ca6-4d97-8fcd-88ef69781c75",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "predictor.fit(\n",
    "    train_path,\n",
    "    hyperparameters={\n",
    "        \"optimization.learning_rate\": 5e-6, # we use two stage and detection head has 100x lr\n",
    "        \"optimization.max_epochs\": 1,   # for the real use case, at least 50\n",
    "        \"optimization.check_val_every_n_epoch\": 1, # make sure there is at least one validation\n",
    "        \"env.per_gpu_batch_size\": 2,  # decrease it when model is large\n",
    "    },\n",
    ")\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0015a20-18d5-4fb5-9b7b-d3b5e38a317f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"This finetuning takes %.2f seconds.\" % (end - start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ef37d6-5059-43c5-b1d7-a0b7a32f1148",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e262995f-b65a-4994-8e90-daae517536b4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load Trained Predictor from S3\n",
    "# zip_file = \"https://automl-mm-bench.s3.amazonaws.com/object_detection/checkpoints/pothole_AP50_718.zip\"\n",
    "# download_dir = \"./pothole_AP50_718\"\n",
    "# load_zip.unzip(zip_file, unzip_dir=download_dir)\n",
    "# better_predictor = MultiModalPredictor.load(\"./pothole_AP50_718/AutogluonModels/ag-20221123_021130\") # 저자들이 미리 50 epoch으로 학습한 모델이다.\n",
    "better_predictor = MultiModalPredictor.load(\"./AutogluonModels/ag-20230327_141514/\")   # yolox 150 epoch\n",
    "better_predictor.set_num_gpus(1)\n",
    "\n",
    "# Evaluate new predictor\n",
    "better_predictor.evaluate(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fa7ab82-64bf-4c87-a221-c5d936990fed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = better_predictor.predict(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4886b38-35db-4c8d-83f0-574faa31d3c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b504810a-ecca-404a-95f7-9c2247571ef8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from autogluon.multimodal.utils import visualize_detection\n",
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "conf_threshold = 0.25  # Specify a confidence threshold to filter out unwanted boxes\n",
    "visualization_result_dir = \"./pothole-test-sample\"  # Use the pwd as result dir to save the visualized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c616cd79-9c33-4950-8e45-1b5f61fefd08",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "visualized = visualize_detection(\n",
    "    pred=pred.iloc[:30],\n",
    "    detection_classes=predictor.get_predictor_classes(),\n",
    "    conf_threshold=conf_threshold,\n",
    "    visualization_result_dir=visualization_result_dir,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6fc8df0-427d-4943-a00a-23bef4266e8f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i in range(30):\n",
    "    img = Image.fromarray(visualized[i][:, :, ::-1], 'RGB')\n",
    "    display(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cb5c32-8680-4b7d-bb8b-3d572c798f99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7faeb1a-f63d-4ae6-8060-985addb0d6b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f793b6-d531-4fc2-960b-b1afb59a07e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
