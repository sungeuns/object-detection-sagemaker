{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "59a74176-938d-4de7-8640-245cf09bfca6",
   "metadata": {},
   "source": [
    "## Jumpstart OD finetuning\n",
    "\n",
    "- Jumpstart를 활용하여 pre-trained 된 모델을 곧바로 배포하거나, fine-tuning하여 활용할 수 있습니다.\n",
    "- [코드 예시](https://github.com/aws/amazon-sagemaker-examples/blob/main/introduction_to_amazon_algorithms/jumpstart_object_detection/Amazon_JumpStart_Object_Detection.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b4bbd-fb5a-484c-89f1-ab7fcaad905f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install sagemaker ipywidgets --upgrade --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4397b1ae-ed69-467c-9ff3-161bbf12f587",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sagemaker, boto3, json\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "aws_role = get_execution_role()\n",
    "aws_region = boto3.Session().region_name\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad78003-b279-4924-bb50-d28c5674a39e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython\n",
    "from ipywidgets import Dropdown\n",
    "\n",
    "# download JumpStart model_manifest file.\n",
    "boto3.client(\"s3\").download_file(\n",
    "    f\"jumpstart-cache-prod-{aws_region}\", \"models_manifest.json\", \"models_manifest.json\"\n",
    ")\n",
    "with open(\"models_manifest.json\", \"rb\") as json_file:\n",
    "    model_list = json.load(json_file)\n",
    "\n",
    "# filter-out all the Object Detection models from the manifest list.\n",
    "od_models = []\n",
    "for model in model_list:\n",
    "    model_id = model[\"model_id\"]\n",
    "    if (\"-od-\" in model_id or \"-od1-\" in model_id) and model_id not in od_models:\n",
    "        od_models.append(model_id)\n",
    "\n",
    "print(f\"Number of available models: {len(model_list)}\")        \n",
    "print(f\"Number of models available for object detection inference: {len(od_models)}\")\n",
    "\n",
    "# display the model-ids in a dropdown to select a model for inference.\n",
    "infer_model_dropdown = Dropdown(\n",
    "    options=od_models,\n",
    "    value=\"pytorch-od-nvidia-ssd\",\n",
    "    description=\"Select a model:\",\n",
    "    style={\"description_width\": \"initial\"},\n",
    "    layout={\"width\": \"max-content\"},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38cd6195-f18e-4e79-9cb3-add71876deb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "display(IPython.display.Markdown(\"### 아래에서 사용할 pre-trained 모델을 선택해 주세요\"))\n",
    "display(infer_model_dropdown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e70ecc7-d9f4-4f94-ab86-d91699ff6de4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(infer_model_dropdown.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8281eb-8e96-4963-81a0-c39e3ce5a0db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris, hyperparameters\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.predictor import Predictor\n",
    "from sagemaker.utils import name_from_base\n",
    "\n",
    "# model_version=\"*\" fetches the latest version of the model\n",
    "infer_model_id, infer_model_version = infer_model_dropdown.value, \"*\"\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-object-detection-infer-{infer_model_id}\")\n",
    "\n",
    "# inference_instance_type = \"ml.m5.2xlarge\"  # cpu 모델 배포시 request 부분도 그에 맞도록 변경\n",
    "inference_instance_type = \"ml.g4dn.2xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,  # automatically inferred from model_id\n",
    "    image_scope=\"inference\",\n",
    "    model_id=infer_model_id,\n",
    "    model_version=infer_model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "\n",
    "# Retrieve the inference script uri. This includes scripts for model loading, inference handling etc.\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=infer_model_id, model_version=infer_model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "# Retrieve the base model uri\n",
    "base_model_uri = model_uris.retrieve(\n",
    "    model_id=infer_model_id, model_version=infer_model_version, model_scope=\"inference\"\n",
    ")\n",
    "\n",
    "# Create the SageMaker model instance\n",
    "model = Model(\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    model_data=base_model_uri,\n",
    "    entry_point=\"inference.py\",  # entry point file in source_dir and present in deploy_source_uri\n",
    "    role=aws_role,\n",
    "    predictor_cls=Predictor,\n",
    "    name=endpoint_name,\n",
    ")\n",
    "\n",
    "# deploy the Model. Note that we need to pass Predictor class when we deploy model through Model class,\n",
    "# for being able to run inference through the sagemaker API.\n",
    "base_model_predictor = model.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    predictor_cls=Predictor,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b565dba0-a2d4-4512-85ac-a242ff83e632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def query(model_predictor, image_file_name):\n",
    "\n",
    "    with open(image_file_name, \"rb\") as file:\n",
    "        input_img_rb = file.read()\n",
    "\n",
    "    query_response = model_predictor.predict(\n",
    "        input_img_rb,\n",
    "        {\n",
    "            \"ContentType\": \"application/x-image\",\n",
    "            \"Accept\": \"application/json;verbose;n_predictions=5\",\n",
    "            # \"Accept\": \"application/json;verbose\",\n",
    "        },\n",
    "    )\n",
    "    return query_response\n",
    "\n",
    "def parse_response(query_response):\n",
    "    model_predictions = json.loads(query_response)\n",
    "    normalized_boxes, classes, scores, labels = (\n",
    "        model_predictions[\"normalized_boxes\"],\n",
    "        model_predictions[\"classes\"],\n",
    "        model_predictions[\"scores\"],\n",
    "        model_predictions[\"labels\"],\n",
    "    )\n",
    "    # Substitute the classes index with the classes name\n",
    "    class_names = [labels[int(idx)] for idx in classes]\n",
    "    return normalized_boxes, class_names, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a725fd-c6c6-48fc-90ed-bc55acf52a8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as patches\n",
    "from matplotlib import pyplot as plt\n",
    "from PIL import Image\n",
    "from PIL import ImageColor\n",
    "import numpy as np\n",
    "\n",
    "conf_threshold = 0.25\n",
    "\n",
    "def display_predictions(img_jpg, normalized_boxes, classes_names, confidences):\n",
    "    colors = list(ImageColor.colormap.values())\n",
    "    image_np = np.array(Image.open(img_jpg))\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    ax = plt.axes()\n",
    "    ax.imshow(image_np)\n",
    "\n",
    "    for idx in range(len(normalized_boxes)):\n",
    "        left, bot, right, top = normalized_boxes[idx]\n",
    "        if confidences[i] >= conf_threshold:\n",
    "            x, w = [val * image_np.shape[1] for val in [left, right - left]]\n",
    "            y, h = [val * image_np.shape[0] for val in [bot, top - bot]]\n",
    "            color = colors[hash(classes_names[idx]) % len(colors)]\n",
    "            rect = patches.Rectangle((x, y), w, h, linewidth=3, edgecolor=color, facecolor=\"none\")\n",
    "            ax.add_patch(rect)\n",
    "            ax.text(\n",
    "                x,\n",
    "                y,\n",
    "                \"{} {:.0f}%\".format(classes_names[idx], confidences[idx] * 100),\n",
    "                bbox=dict(facecolor=\"white\", alpha=0.5),\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e20c513-7dea-44de-b943-c77fb81b1baa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "image_dir = os.path.join(\"data\", \"tiny_motorbike\", \"JPEGImages\")\n",
    "test_images = os.listdir(image_dir)\n",
    "random.shuffle(test_images)\n",
    "\n",
    "for i in range(3):\n",
    "    test_image = os.path.join(image_dir, test_images[i])\n",
    "    query_response = query(base_model_predictor, test_image)\n",
    "    normalized_boxes, classes_names, confidences = parse_response(query_response)\n",
    "    display_predictions(test_image, normalized_boxes, classes_names, confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071c28a7-1db2-456d-86a2-dc66ef5742c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6ff3fa80-63ff-4db5-9616-46c4c9cd3768",
   "metadata": {},
   "source": [
    "### Jumpstart를 활용하여 fine-tuning 진행\n",
    "\n",
    "- 데이터의 포맷의 변경이 필요합니다.\n",
    "- 받은 데이터의 폴더 구조 변경은 아래와 같이 필요합니다.\n",
    "```\n",
    "input_directory\n",
    "    |--images\n",
    "        |--abc.png\n",
    "        |--def.png\n",
    "    |--annotations.json\n",
    "```\n",
    "- 추가로 bbox format은 `COCO format`인데 `VOC format`으로 변경이 되어야 합니다.\n",
    "- `COCO format` : [x, y, width, height]\n",
    "- `VOC format` : [x_min, y_min, x_max, y_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714233bb-4b45-46d5-a0ca-e269649fe36f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install -q pybboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3162b43b-c39a-4bd7-8cfd-0477d6f3166c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pybboxes as pbx\n",
    "annotation_file = os.path.join(\"data\", \"pothole\", \"Annotations\", \"usersplit_train_cocoformat.json\")\n",
    "with open(annotation_file, 'r') as file:\n",
    "    annotations = json.load(file)\n",
    "    for img in annotations[\"images\"]:\n",
    "        only_name = img[\"file_name\"].split(\"/\")[1]\n",
    "        img[\"file_name\"] = only_name\n",
    "        \n",
    "    for bbox in annotations[\"annotations\"]:\n",
    "        new_bbox = pbx.convert_bbox(bbox[\"bbox\"], from_type=\"coco\", to_type=\"voc\")\n",
    "        # print(bbox[\"bbox\"], list(new_bbox))\n",
    "        bbox[\"bbox\"] = new_bbox\n",
    "        \n",
    "result_file = os.path.join(\"data\", \"pothole\", \"annotations.json\")\n",
    "with open(result_file, 'w', encoding='utf-8') as file:\n",
    "    json.dump(annotations, file)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cf160c-b06b-4a2a-af74-8463ba86d821",
   "metadata": {},
   "source": [
    "- S3에 변경된 annotation 파일 업로드 및 폴더 이름 변경등을 진행하고 학습을 진행할 수 있습니다.\n",
    "- 미리 준비된 fine-tuning 코드를 활용하여 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098bb471-2afb-4750-8fa7-e720f424629c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import image_uris, model_uris, script_uris\n",
    "\n",
    "# Currently, not all the object detection models in jumpstart support finetuning. Thus, we manually select a model\n",
    "# which supports finetuning.\n",
    "train_model_id, train_model_version, train_scope = (\n",
    "    # \"mxnet-od-ssd-512-vgg16-atrous-coco\",\n",
    "    \"pytorch-od1-fasterrcnn-resnet50-fpn\",\n",
    "    \"*\",\n",
    "    \"training\",\n",
    ")\n",
    "training_instance_type = \"ml.p3.2xlarge\"\n",
    "\n",
    "# Retrieve the docker image\n",
    "train_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,  # automatically inferred from model_id\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    image_scope=train_scope,\n",
    "    instance_type=training_instance_type,\n",
    ")\n",
    "\n",
    "# Retrieve the training script. This contains all the necessary files including data processing, model training etc.\n",
    "train_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=train_scope\n",
    ")\n",
    "# Retrieve the pre-trained model tarball to further fine-tune\n",
    "train_model_uri = model_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, model_scope=train_scope\n",
    ")\n",
    "\n",
    "print(train_image_uri)\n",
    "print(train_source_uri)\n",
    "print(train_model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b457ca5f-22c3-4d46-b914-612f8b51d219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_dataset_s3_path = f\"s3://{bucket}/object_detection_data/pothole/\"\n",
    "s3_output_location = f\"s3://{bucket}/jumpstart-od-finetuning/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc96c3d-344c-4738-82ae-22142bf3c321",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker import hyperparameters\n",
    "\n",
    "# Retrieve the default hyper-parameters for fine-tuning the model\n",
    "hyperparameters = hyperparameters.retrieve_default(\n",
    "    model_id=train_model_id, model_version=train_model_version\n",
    ")\n",
    "\n",
    "# [Optional] Override default hyperparameters with custom values\n",
    "hyperparameters[\"epochs\"] = \"10\"\n",
    "print(hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54208014-c045-4726-969b-b84a2bb1f18f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sagemaker.estimator import Estimator\n",
    "from sagemaker.utils import name_from_base\n",
    "from sagemaker.tuner import HyperparameterTuner\n",
    "\n",
    "training_job_name = name_from_base(f\"jumpstart-od-{train_model_id}-transfer-learning\")\n",
    "\n",
    "# Create SageMaker Estimator instance\n",
    "od_estimator = Estimator(\n",
    "    role=aws_role,\n",
    "    image_uri=train_image_uri,\n",
    "    source_dir=train_source_uri,\n",
    "    model_uri=train_model_uri,\n",
    "    entry_point=\"transfer_learning.py\",  # Entry-point file in source_dir and present in train_source_uri.\n",
    "    instance_count=1,\n",
    "    instance_type=training_instance_type,\n",
    "    max_run=360000,\n",
    "    hyperparameters=hyperparameters,\n",
    "    output_path=s3_output_location,\n",
    "    base_job_name=training_job_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f105549b-17b4-4b44-94c4-6471966f6299",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "od_estimator.fit({\"training\": training_dataset_s3_path}, logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ce1259-b576-4daa-a5de-44931d41cb33",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "inference_instance_type = \"ml.p3.2xlarge\"\n",
    "\n",
    "# Retrieve the inference docker container uri\n",
    "deploy_image_uri = image_uris.retrieve(\n",
    "    region=None,\n",
    "    framework=None,  # automatically inferred from model_id\n",
    "    image_scope=\"inference\",\n",
    "    model_id=train_model_id,\n",
    "    model_version=train_model_version,\n",
    "    instance_type=inference_instance_type,\n",
    ")\n",
    "\n",
    "# Retrieve the inference script uri. This includes scripts for model loading, inference handling etc.\n",
    "deploy_source_uri = script_uris.retrieve(\n",
    "    model_id=train_model_id, model_version=train_model_version, script_scope=\"inference\"\n",
    ")\n",
    "\n",
    "endpoint_name = name_from_base(f\"jumpstart-od-endpoint-{train_model_id}-\")\n",
    "\n",
    "# Use the estimator from the previous step to deploy to a SageMaker endpoint\n",
    "predictor = od_estimator.deploy(\n",
    "    initial_instance_count=1,\n",
    "    instance_type=inference_instance_type,\n",
    "    entry_point=\"inference.py\",  # entry point file in source_dir and present in deploy_source_uri\n",
    "    image_uri=deploy_image_uri,\n",
    "    source_dir=deploy_source_uri,\n",
    "    endpoint_name=endpoint_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13636d8-ca43-4a59-8f03-77a035120579",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_dir = os.path.join(\"data\", \"pothole\", \"JPEGImages\")\n",
    "test_images = os.listdir(image_dir)\n",
    "random.shuffle(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d680cc74-b24c-493a-a386-35084ee88003",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "for i in range(5):\n",
    "    test_image = os.path.join(image_dir, test_images[i])\n",
    "    Image.open(test_image).convert('RGB').save(test_image)  # alpha channel 있는 경우 에러 발생하므로 추가함. \n",
    "    query_response = query(predictor, test_image)\n",
    "    normalized_boxes, classes_names, confidences = parse_response(query_response)\n",
    "    display_predictions(test_image, normalized_boxes, classes_names, confidences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22221928-03de-487c-a8fd-8f7fb9d21051",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c2635d-6b93-42df-a5fc-93cc07a9bce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
